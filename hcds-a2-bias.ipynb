{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Preprocessing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I am reading the page_data and WPDS csv files to preprocess the data.\n",
    "2. I add a new column called keep, that removes all the data points where the word 'Template' is in the page column. These articles are not to be processed.\n",
    "3. I filter the data frame to keep only the records which do not have the word 'Template' in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data = pd.read_csv('page_data.csv')\n",
    "\n",
    "world_population_data = pd.read_csv('WPDS_2018_data.csv')\n",
    "\n",
    "#This function returns 1 if word is found in the row\n",
    "#Here , row refers to the page column in the dataset and word refers to 'Template'\n",
    "def filter_rows(row, word):\n",
    "    if word in row:\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "#Adding a keep column to the page_data dataframe to decide which rows to keep and which rows to omit\n",
    "page_data['keep'] = page_data.apply(lambda x: filter_rows(x['page'], 'Template'), axis=1)\n",
    "\n",
    "#Filtering the page_data dataframe based on the values in the keep column\n",
    "#Keep = 0: record does not contain 'Template', Keep = 1: record contains 'Template'\n",
    "page_data = page_data[page_data['keep'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Predicting the article quality__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here, I will use the API to get the article quality predictions for each article in our preprocessed dataset.\n",
    "2. We will add an 'article quality' column in the page_data dataframe that assigns an article quality to each rev_id\n",
    "3. For some rev_ids, we do not have an article quality returned. We add a try catch block to keep a track of these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent' : 'https://github.com/yashkale94', 'From' : 'yashkale@uw.edu'}\n",
    "\n",
    "def get_ores_data(revision_ids, headers):\n",
    "    \n",
    "    endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}'\n",
    "    params = {'project' : 'enwiki',\n",
    "              'model'   : 'wp10',\n",
    "              'revids'  : '|'.join(str(x) for x in revision_ids)\n",
    "              }\n",
    "    api_call = requests.get(endpoint.format(**params))\n",
    "    response = api_call.json()\n",
    "    return(response)\n",
    "    \n",
    "rev_ids = page_data['rev_id'].values\n",
    "low = 0\n",
    "high = 100\n",
    "scores = []\n",
    "flag = 0\n",
    "while(True):\n",
    "    \n",
    "    #Get predictions for each rev_id in batches of 100\n",
    "    predictions = get_ores_data(rev_ids[low:high], headers)\n",
    "    \n",
    "    #Access the scores for the given rev_ids\n",
    "    predictions = predictions['enwiki']['scores']\n",
    "    \n",
    "    #Checks if we have reached the end of the list of rev_ids\n",
    "    if high > len(rev_ids):\n",
    "        high = len(rev_ids)\n",
    "        flag = 1\n",
    "        \n",
    "    #Try catch block to check for rev_ids that do not return any score/prediction\n",
    "    for revid in rev_ids[low:high]:\n",
    "        try:\n",
    "            score = predictions[str(revid)]['wp10']['score']['prediction']\n",
    "            scores.append(score)\n",
    "        except:\n",
    "            scores.append('No score found')\n",
    "    if flag == 1:\n",
    "        break\n",
    "    low+=100\n",
    "    high+=100\n",
    "    \n",
    "#We add a new article quality column to our page_data dataframe\n",
    "page_data['article_quality'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Merging of the two dataframes for final dataframe__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We want to create a final dataframe for our analysis. For this, we merge the page_data and world_population_data dataframes.\n",
    "2. We create two new columns in the page_data dataframe, namely: 'Region' and 'Population'. This stores the region and population of the country the article that falls in.\n",
    "3. We use a try catch block to take care of those articles that do not have a country or population associated with it in the world_population_data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the two columns of world_population_data dataframe in a list\n",
    "region_country = world_population_data[['Geography','Population mid-2018 (millions)']].values\n",
    "count = 0\n",
    "\n",
    "#Create a dictionary to keep the map of every country to the region it belongs to\n",
    "#If the name is in block letters, it is a region name and not a country name\n",
    "country_to_region_map = {}\n",
    "for i in region_country:\n",
    "    if i[0].isupper():\n",
    "        key = i[0]\n",
    "    else:\n",
    "        country_to_region_map[i[0]] = [key, i[1]]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list = []\n",
    "population_list = []\n",
    "\n",
    "#We iterate on the page_data dataframe to create two columns, that store the population and region name for each country\n",
    "for index, row in page_data.iterrows():\n",
    "    try:\n",
    "        region, population = country_to_region_map[row.values[1]]\n",
    "        region_list.append(region)\n",
    "        population_list.append(population)\n",
    "    except:\n",
    "        #If we do not have a corresponding population for a country, we add 'Population not found'\n",
    "        region_list.append('Country not found')\n",
    "        population_list.append('Population not found')    \n",
    "        \n",
    "page_data['Region'] = region_list\n",
    "page_data['Population'] = population_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data.drop(columns=['Region'], inplace=True)\n",
    "page_data = page_data[['country', 'page','rev_id','article_quality', 'Population']]\n",
    "data_not_found = page_data[(page_data['article_quality'] == 'No score found') | (page_data['Population'] == 'Population not found')]\n",
    "page_data_complete = page_data[(page_data['article_quality'] != 'No score found') & (page_data['Population'] != 'Population not found')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculating the countries by coverage__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here, we use a dictionary to keep a map of number of articles per country.\n",
    "2. We then use the information we have about the population of each country to calculate the coverage per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a dictionary to store country:articles as key value pair\n",
    "articles_per_country = defaultdict(int)\n",
    "for i, row in page_data_complete.iterrows():\n",
    "    country = row.values[0]\n",
    "    articles_per_country[country]+=1\n",
    "\n",
    "#creates a list to store the countries and their articles coverage\n",
    "proportion_country = []\n",
    "for country, value in articles_per_country.items():\n",
    "    country_population = country_to_region_map[country][1]\n",
    "    \n",
    "    #Removes the character ',' from the population and converts it to float so that we can add the population value later\n",
    "    country_population = float(country_population.replace(',',''))\n",
    "    \n",
    "    #Population values are in millions. Hence we multiply by 10^6\n",
    "    proportion_country.append((country, value/(country_population*10**6)))\n",
    "\n",
    "#This gives us the top 10 countries by their coverage\n",
    "top_countries = sorted(proportion_country, key = lambda x: (x[1]), reverse=True)[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Top 10 countries by coverage percentage__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nauru</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>0.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liechtenstein</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>0.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>0.061667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>0.050250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grenada</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Country  Coverage\n",
       "0            Tuvalu  0.540000\n",
       "1             Nauru  0.520000\n",
       "2        San Marino  0.270000\n",
       "3            Monaco  0.100000\n",
       "4     Liechtenstein  0.070000\n",
       "5             Tonga  0.063000\n",
       "6  Marshall Islands  0.061667\n",
       "7           Iceland  0.050250\n",
       "8           Andorra  0.042500\n",
       "9           Grenada  0.036000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(top_countries, columns=['Country','Coverage'])\n",
    "df['Coverage'] = df['Coverage']*100\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bottom 10 countries by coverage percentage:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mozambique</td>\n",
       "      <td>0.000190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country  Coverage\n",
       "0         India  0.000071\n",
       "1     Indonesia  0.000079\n",
       "2         China  0.000081\n",
       "3    Uzbekistan  0.000085\n",
       "4      Ethiopia  0.000094\n",
       "5  Korea, North  0.000141\n",
       "6        Zambia  0.000141\n",
       "7      Thailand  0.000169\n",
       "8    Mozambique  0.000190\n",
       "9    Bangladesh  0.000192"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_countries = sorted(proportion_country, key = lambda x: (x[1]))[0:10]\n",
    "df = pd.DataFrame(bottom_countries, columns=['Country','Coverage'])\n",
    "df['Coverage'] = df['Coverage']*100\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "__Calculating countries based on the coverage of GA/FA articles__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here, we want to calculate the relative quality of countries, based on the number of GA/FA articles published in these countries.\n",
    "2. We create a dictionary that will store the GA/FA articles per country as a key value pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#We filter on the dataframe to keep only those records that have atleast one GA/FA article\n",
    "page_data_high = page_data_complete[(page_data_complete['article_quality'] == 'GA') | (page_data_complete['article_quality'] == 'FA')]\n",
    "\n",
    "#We create a dictionary to store the number of high quality articles per country\n",
    "high_rated_articles = defaultdict(int)\n",
    "for i, row in page_data_high.iterrows():\n",
    "    article_quality = row.values[3]\n",
    "    country = row.values[0]\n",
    "    high_rated_articles[country]+=1\n",
    "\n",
    "high_rated_articles_ratio = []\n",
    "for key, value in high_rated_articles.items():\n",
    "    articles_in_country = articles_per_country[key]\n",
    "    high_rated_articles_ratio.append((key, value/articles_in_country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Top 10 countries by relative quality:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Korea, North</td>\n",
       "      <td>19.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>12.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mauritania</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>12.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Romania</td>\n",
       "      <td>11.370262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>9.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dominica</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Syria</td>\n",
       "      <td>7.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Benin</td>\n",
       "      <td>7.692308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Country  article_quality\n",
       "0              Korea, North        19.444444\n",
       "1              Saudi Arabia        12.711864\n",
       "2                Mauritania        12.500000\n",
       "3  Central African Republic        12.121212\n",
       "4                   Romania        11.370262\n",
       "5                    Tuvalu         9.259259\n",
       "6                    Bhutan         9.090909\n",
       "7                  Dominica         8.333333\n",
       "8                     Syria         7.812500\n",
       "9                     Benin         7.692308"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We create a dataframe from a list that sorts the countries based on their relative article_quality\n",
    "top_countries = sorted(high_rated_articles_ratio, key=lambda x: x[1], reverse=True)[0:10]\n",
    "df = pd.DataFrame(top_countries, columns=['Country','article_quality'])\n",
    "df['article_quality'] = df['article_quality']*100\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To calculate the bottom countries, we make sure that we consider countries that have 0 GA/FA articles also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We keep a count of number of articles in each country.\n",
    "#For each country, we keep a track of number of articles in each given article_quality possibility\n",
    "articles_count_country = {}\n",
    "for index, row in page_data_complete.iterrows():\n",
    "    if row.values[0] not in articles_count_country.keys():\n",
    "        articles_count_country[row.values[0]] = {}\n",
    "        articles_count_country[row.values[0]][row.values[3]] = 1\n",
    "    else:\n",
    "        if row.values[3] not in articles_count_country[row.values[0]].keys():\n",
    "            articles_count_country[row.values[0]][row.values[3]] = 1\n",
    "        else:\n",
    "            articles_count_country[row.values[0]][row.values[3]]+=1\n",
    "\n",
    "#With this, we make sure we add 0 to those countries that do not have GA or FA in them\n",
    "for key, value in articles_count_country.items():\n",
    "    if 'GA' not in value.keys():\n",
    "        articles_count_country[key]['GA'] = 0\n",
    "    if 'FA' not in value.keys():\n",
    "        articles_count_country[key]['FA'] = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bottom 10 countries by relative quality:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malta</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finland</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tunisia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Slovakia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country  article_quality\n",
       "0         Malta              0.0\n",
       "1        Angola              0.0\n",
       "2       Finland              0.0\n",
       "3       Tunisia              0.0\n",
       "4    San Marino              0.0\n",
       "5        Uganda              0.0\n",
       "6       Moldova              0.0\n",
       "7        Monaco              0.0\n",
       "8  Turkmenistan              0.0\n",
       "9      Slovakia              0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_rated_articles_ratio = []\n",
    "for key, value in articles_per_country.items():\n",
    "    high_rated_articles = articles_count_country[key]['GA'] + articles_count_country[key]['FA']\n",
    "    high_rated_articles_ratio.append((key,high_rated_articles/articles_per_country[key]))\n",
    "    \n",
    "bottom_countries = sorted(high_rated_articles_ratio, key=lambda x: x[1])[0:10]\n",
    "df = pd.DataFrame(bottom_countries, columns=['Country','article_quality'])\n",
    "df['article_quality'] = df['article_quality']*100\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Now, we want to calculate the similar metrics at a geographical region\n",
    "2. For this, we require the number of articles in the geogrpahical region.\n",
    "3. We maintain a dictionary that stores the number of articles in a given region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#We create a dictionary to store articles per region\n",
    "articles_by_region = defaultdict(int)\n",
    "for key, value in articles_per_country.items():\n",
    "    region_population = country_to_region_map[key][1]\n",
    "    region_articles = value\n",
    "    articles_by_region[country_to_region_map[key][0]]+=value\n",
    "\n",
    "#We create a dictionary to store the population in every region\n",
    "population_by_region = defaultdict(int)\n",
    "for key, value in articles_per_country.items():\n",
    "    region_population = country_to_region_map[key][1]\n",
    "    region_population = region_population.replace(',','')\n",
    "    population_by_region[country_to_region_map[key][0]]+=(float(region_population))*10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each region, we store the population. We converted the string value to a float value and multiply by 10^6, as the population\n",
    "#is in millions\n",
    "africa_population = world_population_data[world_population_data['Geography'] == 'AFRICA']['Population mid-2018 (millions)'].values[0]\n",
    "northern_america = world_population_data[world_population_data['Geography'] == 'NORTHERN AMERICA']['Population mid-2018 (millions)'].values[0]\n",
    "latin_america = world_population_data[world_population_data['Geography'] == 'LATIN AMERICA AND THE CARIBBEAN']['Population mid-2018 (millions)'].values[0]\n",
    "asia = world_population_data[world_population_data['Geography'] == 'ASIA']['Population mid-2018 (millions)'].values[0]\n",
    "europe = world_population_data[world_population_data['Geography'] == 'EUROPE']['Population mid-2018 (millions)'].values[0]\n",
    "oceania = world_population_data[world_population_data['Geography'] == 'OCEANIA']['Population mid-2018 (millions)'].values[0]\n",
    "\n",
    "africa_population = float(africa_population.replace(',',''))*10**6\n",
    "northern_america = float(northern_america.replace(',',''))*10**6\n",
    "latin_america = float(latin_america.replace(',',''))*10**6\n",
    "asia = float(asia.replace(',',''))*10**6\n",
    "europe = float(europe.replace(',',''))*10**6\n",
    "oceania = float(oceania.replace(',',''))*10**6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Geographic regions by coverage:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_regions_order = []\n",
    "articles_regions_order.append(('AFRICA', articles_by_region['AFRICA']/ africa_population))\n",
    "articles_regions_order.append(('NORTHERN AMERICA', articles_by_region['NORTHERN AMERICA']/ northern_america))\n",
    "articles_regions_order.append(('LATIN AMERICA AND THE CARIBBEAN', articles_by_region['LATIN AMERICA AND THE CARIBBEAN']/ latin_america))\n",
    "articles_regions_order.append(('ASIA', articles_by_region['ASIA']/ asia))\n",
    "articles_regions_order.append(('EUROPE', articles_by_region['EUROPE']/ europe))\n",
    "articles_regions_order.append(('OCEANIA', articles_by_region['OCEANIA']/ oceania))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Top 10 Geographic regions by coverage percentage__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>0.007629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUROPE</td>\n",
       "      <td>0.002127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LATIN AMERICA AND THE CARIBBEAN</td>\n",
       "      <td>0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>0.000534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NORTHERN AMERICA</td>\n",
       "      <td>0.000526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASIA</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Region  Coverage\n",
       "0                          OCEANIA  0.007629\n",
       "1                           EUROPE  0.002127\n",
       "2  LATIN AMERICA AND THE CARIBBEAN  0.000796\n",
       "3                           AFRICA  0.000534\n",
       "4                 NORTHERN AMERICA  0.000526\n",
       "5                             ASIA  0.000254"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_regions = sorted(articles_regions_order, key=lambda x: x[1], reverse=True)\n",
    "df = pd.DataFrame(top_regions, columns=['Region','Coverage'])\n",
    "df['Coverage'] = df['Coverage']*100\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we store the number of high quality articles per region in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a dictionary to store the number of high quality articles per country\n",
    "high_rated_articles = defaultdict(int)\n",
    "for i, row in page_data_high.iterrows():\n",
    "    article_quality = row.values[3]\n",
    "    country = row.values[0]\n",
    "    high_rated_articles[country]+=1\n",
    "\n",
    "high_articles_regionwise = defaultdict(int)\n",
    "for key, value in high_rated_articles.items():\n",
    "    high_articles_regionwise[country_to_region_map[key][0]]+=value\n",
    "\n",
    "high_articles_regionwise_order = []\n",
    "high_articles_regionwise_order.append(('AFRICA',high_articles_regionwise['AFRICA']/ articles_by_region['AFRICA']))\n",
    "high_articles_regionwise_order.append(('NORTHERN AMERICA',high_articles_regionwise['NORTHERN AMERICA']/ articles_by_region['NORTHERN AMERICA']))\n",
    "high_articles_regionwise_order.append(('LATIN AMERICA AND THE CARIBBEAN',high_articles_regionwise['LATIN AMERICA AND THE CARIBBEAN']/ articles_by_region['LATIN AMERICA AND THE CARIBBEAN']))\n",
    "high_articles_regionwise_order.append(('ASIA',high_articles_regionwise['ASIA']/ articles_by_region['ASIA']))\n",
    "high_articles_regionwise_order.append(('EUROPE',high_articles_regionwise['EUROPE']/ articles_by_region['EUROPE']))\n",
    "high_articles_regionwise_order.append(('OCEANIA',high_articles_regionwise['OCEANIA']/ articles_by_region['OCEANIA']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Top 10 Geographic regions by relative article quality__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORTHERN AMERICA</td>\n",
       "      <td>5.153566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASIA</td>\n",
       "      <td>2.688405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>2.109974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUROPE</td>\n",
       "      <td>2.029753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>1.824551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LATIN AMERICA AND THE CARIBBEAN</td>\n",
       "      <td>1.334881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Region  article_quality\n",
       "0                 NORTHERN AMERICA         5.153566\n",
       "1                             ASIA         2.688405\n",
       "2                          OCEANIA         2.109974\n",
       "3                           EUROPE         2.029753\n",
       "4                           AFRICA         1.824551\n",
       "5  LATIN AMERICA AND THE CARIBBEAN         1.334881"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_regions = sorted(high_articles_regionwise_order, key=lambda x: x[1], reverse=True)\n",
    "df = pd.DataFrame(top_regions, columns=['Region','article_quality'])\n",
    "df['article_quality'] = df['article_quality']*100\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We store the results of those records, that do not have population data, or do not have any articles by their name in a different file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data1 = pd.read_csv('page_data.csv')\n",
    "\n",
    "world_population_data1 = pd.read_csv('WPDS_2018_data.csv')\n",
    "\n",
    "no_population = page_data[page_data['Population'] == 'Population not found']\n",
    "countries_article = set(page_data1['country'].values)\n",
    "\n",
    "#We filter the countries who do not have corresponding article data\n",
    "def filter_countries(country, countries):\n",
    "    if country not in countries:\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "world_population_data1['keep'] = world_population_data1.apply(lambda x: filter_countries(x['Geography'], countries_article), axis=1)\n",
    "world_population_data1 = world_population_data1[world_population_data1['keep'] == 1]\n",
    "\n",
    "#We add another rev_id column in the population data so that we can merge this with the page_data dataframe\n",
    "world_population_data1['rev_id'] = 'No Articles found'\n",
    "\n",
    "world_population_data1 = world_population_data1[['Geography','Population mid-2018 (millions)','rev_id']]\n",
    "no_population = no_population[['country', 'Population', 'rev_id']]\n",
    "\n",
    "df_final = pd.concat([no_population, world_population_data1.rename(columns={'Geography':'country','Population mid-2018 (millions)'\n",
    "                                                                    :'Population'})], ignore_index=True)\n",
    "\n",
    "#We then store these records that have no match in a file\n",
    "df_final.to_csv('wp_wpds_countries-no_match.csv', index=False)\n",
    "\n",
    "#We store the data for which we have performed analysis and have entire data available in another separate file.\n",
    "page_data_complete.to_csv('wp_wpds_politicians_by_country.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__FINAL ANALYSIS__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initially when I began parsing the dataset, I could see that there a lot of discrepancies. The way country names are defined in both the data sources is not constant. That creates a problem when identifying the same country.\n",
    "2. The way the regions are stored in the data files is extremely inefficient. The only map from the country to its region is that in the WPDS_2018_data file, regions are marked by capital letters and countries with capital and small letters. This is not a good dataset to work with, since it requires a lot of cleaning.\n",
    "3. There are some revision_ids that do not return any ORES score, even though they are not of the 'Template' form. It does not state any reason as to why this score is not available for such articles. This makes me question which articles are suitable to generate an ORES score for.\n",
    "4. I expected some bias in this dataset, where the countries with large populations and growing economies, I expected them to have a higher relative quality ratio than other countries. On the contrary, I found that these countries had a lower relatice quality ratio. I expected this bias, because I thought larger the countries, there would be a higher chance the articles would be of higher quality.\n",
    "5. I believe this dataset, with a little bit of cleaning can be used to correlate the findings of high quality articles in countries to their respective literacy rates. I think we could see an interesting correlation there, which might suggest that higher literacy rates correspond to higher quality articles. \n",
    "6. In my opinion, this dataset is not a very good source as there are so many data points that are misleading. For example, we have the same country Oman listed as Omani in one source and Oman in the other. This is not a good data set as ideally, both would point to the same country Oman, but would fail here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
